#!/usr/bin/env groovy

@Library('apm@current') _

pipeline {
  agent { label 'ubuntu-20.04 && immutable && docker' }
  environment {
    REPO = 'e2e-testing'
    BASE_DIR = "src/github.com/elastic/${env.REPO}"
    ELASTIC_APM_ACTIVE="true"
    ELASTIC_APM_ENVIRONMENT="ci"
    ELASTIC_APM_LOG_FILE="stderr"
    ELASTIC_APM_LOG_LEVEL="debug"
    NIGHTLY_TAG="@nightly"
    NOTIFY_TO = credentials('notify-to')
    JOB_GCS_BUCKET = credentials('gcs-bucket')
    JOB_GIT_CREDENTIALS = "2a9602aa-ab9f-4e52-baf3-b71ca88469c7-UserAndToken"
    DOCKER_ELASTIC_SECRET = 'secret/observability-team/ci/docker-registry/prod'
    DOCKER_REGISTRY = 'docker.elastic.co'
    ELASTIC_CLOUD_SECRET = 'secret/observability-team/ci/elastic-cloud/observability-team'
  }
  options {
    timeout(time: 1, unit: 'HOURS')
    buildDiscarder(logRotator(numToKeepStr: '20', artifactNumToKeepStr: '20', daysToKeepStr: '30'))
    timestamps()
    ansiColor('xterm')
    disableResume()
    durabilityHint('PERFORMANCE_OPTIMIZED')
    rateLimitBuilds(throttle: [count: 60, durationName: 'hour', userBoost: true])
    quietPeriod(10)
  }
  triggers {
    issueCommentTrigger("${obltGitHubComments()}")
  }
  parameters {
    booleanParam(name: 'Run_As_Master_Branch', defaultValue: false, description: 'Allow to run any steps on a PR, some steps normally only run on master branch.')
    booleanParam(name: "SKIP_SCENARIOS", defaultValue: true, description: "If it's needed to skip those scenarios marked as @skip. Default true")
    booleanParam(name: "NIGHTLY_SCENARIOS", defaultValue: false, description: "If it's needed to include the scenarios marked as @nightly in the test execution. Default false")
    string(name: 'runTestsSuites', defaultValue: '', description: 'A comma-separated list of test suites to run (default: empty to run all test suites)')
    booleanParam(name: "forceSkipGitChecks", defaultValue: false, description: "If it's needed to check for Git changes to filter by modified sources")
    booleanParam(name: "forceSkipPresubmit", defaultValue: false, description: "If it's needed to execute the pre-submit tests: unit and precommit.")
    booleanParam(name: "notifyOnGreenBuilds", defaultValue: false, description: "If it's needed to notify to Slack with green builds.")
    string(name: 'SLACK_CHANNEL', defaultValue: 'observablt-bots', description: 'The Slack channel(s) where errors will be posted. For multiple channels, use a comma-separated list of channels')
    string(name: 'ELASTIC_AGENT_DOWNLOAD_URL', defaultValue: '', description: 'If present, it will override the download URL for the Elastic agent artifact. (I.e. https://snapshots.elastic.co/8.0.0-59098054/downloads/beats/elastic-agent/elastic-agent-8.0.0-SNAPSHOT-linux-x86_64.tar.gz')
    string(name: 'BEAT_VERSION', defaultValue: '8.0.0-61c5a306-SNAPSHOT', description: 'SemVer version of the Beat to be used for the tests. You can use here the tag of your PR to test your changes')
    string(name: 'ELASTIC_AGENT_STALE_VERSION', defaultValue: '7.15-SNAPSHOT', description: 'SemVer version of the stale stand-alone elastic-agent to be used for Fleet upgrade tests.')
    choice(name: 'LOG_LEVEL', choices: ['DEBUG', 'TRACE', 'INFO'], description: 'Log level to be used')
    choice(name: 'TIMEOUT_FACTOR', choices: ['5', '3', '7', '11'], description: 'Max number of minutes for timeout backoff strategies')
    string(name: 'KIBANA_VERSION', defaultValue: '', description: 'Docker tag of the kibana to be used for the tests. It will refer to an image related to a Kibana PR, under the Observability-CI namespace')
    string(name: 'STACK_VERSION', defaultValue: '8.0.0-61c5a306-SNAPSHOT', description: 'SemVer version of the stack to be used for the tests.')
    string(name: 'HELM_CHART_VERSION', defaultValue: '7.11.2', description: 'SemVer version of Helm chart to be used.')
    string(name: 'HELM_VERSION', defaultValue: '3.5.2', description: 'SemVer version of Helm to be used.')
    string(name: 'KIND_VERSION', defaultValue: '0.10.0', description: 'SemVer version of Kind to be used.')
    string(name: 'KUBERNETES_VERSION', defaultValue: '1.18.2', description: 'SemVer version of Kubernetes to be used.')
    string(name: 'GITHUB_CHECK_NAME', defaultValue: '', description: 'Name of the GitHub check to be updated. Only if this build is triggered from another parent stream.')
    string(name: 'GITHUB_CHECK_REPO', defaultValue: '', description: 'Name of the GitHub repo to be updated. Only if this build is triggered from another parent stream.')
    string(name: 'GITHUB_CHECK_SHA1', defaultValue: '', description: 'Git SHA for the Beats upstream project (branch or PR)')
  }
  stages {
    stage('Initializing'){
      options { skipDefaultCheckout() }
      environment {
        HOME = "${env.WORKSPACE}"
        PATH = "${env.PATH}:${env.WORKSPACE}/bin:${env.WORKSPACE}/${env.BASE_DIR}/.ci/scripts"
        GO111MODULE = 'on'
        SKIP_SCENARIOS = "${params.SKIP_SCENARIOS}"
        NIGHTLY_SCENARIOS = "${params.NIGHTLY_SCENARIOS}"
        SLACK_CHANNEL = "${params.SLACK_CHANNEL.trim()}"
        ELASTIC_AGENT_DOWNLOAD_URL = "${params.ELASTIC_AGENT_DOWNLOAD_URL.trim()}"
        BEAT_VERSION = "${params.BEAT_VERSION.trim()}"
        KIBANA_VERSION = "${params.KIBANA_VERSION.trim()}"
        STACK_VERSION = "${params.STACK_VERSION.trim()}"
        FORCE_SKIP_GIT_CHECKS = "${params.forceSkipGitChecks}"
        FORCE_SKIP_PRESUBMIT = "${params.forceSkipPresubmit}"
        HELM_CHART_VERSION = "${params.HELM_CHART_VERSION.trim()}"
        HELM_VERSION = "${params.HELM_VERSION.trim()}"
        KIND_VERSION = "${params.KIND_VERSION.trim()}"
        KUBERNETES_VERSION = "${params.KUBERNETES_VERSION.trim()}"
        LOG_LEVEL = "${params.LOG_LEVEL.trim()}"
        TIMEOUT_FACTOR = "${params.TIMEOUT_FACTOR.trim()}"
      }
      stages {
        stage('Checkout') {
          steps {
            pipelineManager([ cancelPreviousRunningBuilds: [ when: 'PR' ] ])
            deleteDir()
            gitCheckout(basedir: BASE_DIR, githubNotifyFirstTimeContributor: true)
            githubCheckNotify('PENDING')  // we want to notify the upstream about the e2e the soonest
            stash allowEmpty: true, name: 'source', useDefaultExcludes: false
            setEnvVar("GO_VERSION", readFile("${env.WORKSPACE}/${env.BASE_DIR}/.go-version").trim())
            dir("${BASE_DIR}"){
              // Skip all the test stages for PR's with markdown changes only
              setEnvVar("SKIP_TESTS", isGitRegionMatch(patterns: [ '.*\\.md' ], shouldMatchAll: true))
            }
          }
        }
        stage('Pre-Submit') {
          when {
            beforeAgent true
            expression { return env.FORCE_SKIP_PRESUBMIT == "false" }
          }
          parallel {
            stage('Sanity checks') {
              agent { label 'ubuntu-18.04 && immutable && docker' }
              environment {
                PATH = "${env.WORKSPACE}/${env.BASE_DIR}/bin:${env.PATH}"
                GO111MODULE = 'auto'
              }
              options { skipDefaultCheckout() }
              steps {
                withGithubNotify(context: 'Sanity checks', tab: 'tests') {
                  deleteDir()
                  unstash 'source'
                  withGoEnv(version: "${GO_VERSION}"){
                    dir(BASE_DIR){
                      retryWithSleep(retries: 2, seconds: 5, backoff: true){ sh script: '.ci/scripts/install-dependencies.sh', label: 'Install dependencies' }
                      preCommit(commit: "${GIT_BASE_COMMIT}", junit: true)
                    }
                  }
                }
              }
            }
            stage('Unit Tests') {
              options { skipDefaultCheckout() }
              when {
                beforeAgent true
                expression { return env.SKIP_TESTS == "false" }
              }
              steps {
                withGithubNotify(context: 'Tests', tab: 'tests') {
                  deleteDir()
                  unstash 'source'
                  withGoEnv(version: "${GO_VERSION}"){
                    dir(BASE_DIR){
                      sh script: '.ci/scripts/build-test.sh', label: 'Build and test'
                    }
                  }
                }
              }
              post {
                always {
                  junit(allowEmptyResults: true, keepLongStdio: true, testResults: "${BASE_DIR}/outputs/TEST-unit-*.xml")
                  archiveArtifacts allowEmptyArchive: true, artifacts: "${BASE_DIR}/outputs/TEST-unit-*.xml"
                }
              }
            }
          }
        }
        stage('Build Docs') {
          options { skipDefaultCheckout() }
          when {
            beforeAgent true
            anyOf {
              expression { return env.FORCE_SKIP_GIT_CHECKS == "true" }
              expression { return env.SKIP_TESTS == "false" }
            }
          }
          steps {
            deleteDir()
            unstash 'source'
            dockerLogin(secret: "${DOCKER_ELASTIC_SECRET}", registry: "${DOCKER_REGISTRY}")
            dir("${BASE_DIR}/e2e") {
              sh(label: 'Build docs', script: 'make build-docs')
            }
          }
          post {
            always {
              dir("${BASE_DIR}") {
                archiveArtifacts allowEmptyArchive: true, artifacts: "e2e/docs/**"
              }
            }
          }
        }
        stage('End-To-End Tests') {
          failFast true
          options { skipDefaultCheckout() }
          environment {
            GO111MODULE = 'on'
            PATH = "${env.HOME}/bin:${env.WORKSPACE}/${env.BASE_DIR}/bin:${HOME}/go/bin:${env.PATH}"
          }
          when {
            beforeAgent true
            anyOf {
              expression { return env.FORCE_SKIP_GIT_CHECKS == "true" }
              expression { return env.SKIP_TESTS == "false" }
            }
          }
          steps {
            withGithubNotify(context: 'E2E Tests', tab: 'tests') {
              deleteDir()
              unstash 'source'
              dir("${BASE_DIR}") {
                script {
                  def suitesParam = params.runTestsSuites
                  def existingSuites = readYaml(file: '.ci/.e2e-tests.yaml')
                  def parallelTasks = [:]

                  if (suitesParam == "") {
                    log(level: 'DEBUG', text: "Iterate through existing test suites")
                    existingSuites['SUITES'].each { item ->
                      checkTestSuite(parallelTasks, item)
                    }
                  } else {
                    log(level: 'DEBUG', text: "Iterate through the comma-separated test suites (${suitesParam}), comparing with the existing test suites")
                    suitesParam.split(',').each { suiteParam ->
                      existingSuites['SUITES'].findAll { suiteParam.trim() == it.suite }.each { item ->
                        checkTestSuite(parallelTasks, item)
                      }
                    }
                  }
                  parallel(parallelTasks)
                }
              }
            }
          }
        }
        stage('Release') {
          options { skipDefaultCheckout() }
          when { tag "v*" }
          steps {
            deleteDir()
            unstash 'source'
            dir("${BASE_DIR}") {
              setEnvVar("GITHUB_TOKEN", getGithubToken())
              retryWithSleep(retries: 2, seconds: 5, backoff: true) {
                sh(label: 'Release binaries with gorelease', script: 'curl -sL https://git.io/goreleaser | bash -s -- --rm-dist', returnStatus: true)
              }
            }
          }
          post {
            always {
              archiveArtifacts allowEmptyArchive: true, artifacts: "${BASE_DIR}/cli/dist/**"
            }
          }
        }
      }
    }
  }
  post {
    cleanup {
      teardownStack()
      doNotifyBuildResult(params.notifyOnGreenBuilds)
    }
  }
}

def withTerraform(Closure body){
  def binDir = "${HOME}/bin"
  withEnv([
    "PATH=${PATH}:${binDir}"
    ]){
      sh(label:'Install Terraform', script: """
        mkdir -p ${binDir}
        cd ${binDir}
        curl -sSL -o terraform.zip https://releases.hashicorp.com/terraform/0.15.3/terraform_0.15.3_linux_amd64.zip
        unzip terraform.zip
      """)
      body()
  }
}

def deployStack(){
    def props = getVaultSecret(secret: "${ELASTIC_CLOUD_SECRET}")
    def authObj = props?.data
    def endpointMap = [:]
    def endpointAddress = null
    withEnvMask(vars: [
        [var: "EC_API_KEY", password: "${authObj.apiKey}"]
    ]) {
        withTerraForm(){
            sh(label: 'Deploy Stack', script: 'terraform -chdir ".ci/terraform/stack" apply -auto-approve')
            endpointAddress = sh(label: 'Get Cloud endpoint', script: "echo ec_deployment.end-to-end.apm[0].https_endpoint | terraform console", returnStdout: true)?.trim()
            if(endpointAddress) {
                endpointMap = [elasticsearchUrl: endpointAddress.replace("\\.apm", ""),
                               kibanaUrl: endpointAddress.replace("\\.apm", ""),
                               fleetUrl: endpointAddress.replace("\\.apm", "\\.fleet")]
            }
        }
    }
    return endpointMap
}

def teardownStack(){
    def props = getVaultSecret(secret: "${ELASTIC_CLOUD_SECRET}")
    def authObj = props?.data
    def endpointMap = [:]
    def endpointAddress = null
    withEnvMask(vars: [
        [var: "EC_API_KEY", password: "${authObj.apiKey}"]
    ]) {
        withTerraForm(){
            sh(label: 'Teardown Stack', script: 'terraform -chdir ".ci/terraform/stack" destroy -auto-approve')
        }
    }
}

def checkTestSuite(Map parallelTasks = [:], Map item = [:]) {
    def suite = item.suite
    def platforms = item.platforms
    def endpointMap = [:]

    // Start stack with fleet server enabled for the fleet suite of tests
    if (suite == "fleet") {
        if(isInstalled(tool: 'docker', flag: '--version')) {
            dockerLogin(secret: "${DOCKER_ELASTIC_SECRET}", registry: "${DOCKER_REGISTRY}")
        }
        filebeat(output: "docker_logs_${suite}.log", workdir: "${env.WORKSPACE}") {
            endpointMap = deployStack()
        }
    }

    item.scenarios.each { scenario ->
      def name = scenario.name
      def platformsValue = platforms
      def scenarioPlatforms = scenario.platforms
      if (scenarioPlatforms?.size() > 0) {
        // scenario platforms take precedence over suite platforms, overriding them
        platformsValue = scenarioPlatforms
      }
      def pullRequestFilter = scenario.containsKey('pullRequestFilter') ? scenario.pullRequestFilter : ''
      def tags = scenario.tags
      def regexps = [ "^e2e/_suites/${suite}/.*", "^.ci/.*", "^cli/.*", "^e2e/.*\\.go", "^internal/.*\\.go" ]
      if ("${FORCE_SKIP_GIT_CHECKS}" == "true" || isGitRegionMatch(patterns: regexps, shouldMatchAll: false)) {
        platformsValue.each { platform ->
          def platformLabels = platform.labels
          log(level: 'INFO', text: "Adding ${platformLabels}:${suite}:${tags} test suite to the build execution")
                parallelTasks["${platformLabels}_${suite}_${tags}"] = generateFunctionalTestStep(name: "${name}", platform: platform,  suite: "${suite}", tags: "${tags}", pullRequestFilter: "${pullRequestFilter}", endpointMap: endpointMap)
        }
      } else {
        log(level: 'WARN', text: "The ${suite}:${tags} test suite won't be executed in any platform because there are no modified files")
      }
    }
}

def doNotifyBuildResult(boolean slackNotify) {
  githubCheckNotify(currentBuild.currentResult == 'SUCCESS' ? 'SUCCESS' : 'FAILURE')

  def testsSuites = "${params.runTestsSuites}"
  if (testsSuites?.trim() == "") {
    testsSuites = "All suites"
  }

  def channels = "${env.SLACK_CHANNEL}"
  if (channels?.trim() == "") {
    channels = "observablt-bots"
  }

  def header = "*Test Suite*: " + testsSuites
  notifyBuildResult(analyzeFlakey: true, jobName: getFlakyJobName(withBranch: "${env.JOB_BASE_NAME}"), prComment: true, slackHeader: header, slackChannel: "${channels}", slackComment: true, slackNotify: slackNotify)
}

def generateFunctionalTestStep(Map args = [:]){
  def name = args.get('name')
  def platform = args.get('platform')
  def suite = args.get('suite')
  def tags = args.get('tags')
  def pullRequestFilter = args.get('pullRequestFilter')?.trim() ? args.get('pullRequestFilter') : ''
  def endpointMap = args.get('endpointMap') ? args.get('endpointMap') : [:]

  def platformLabels = platform.labels
  def platformProvider = platform.provider

  if (!platformProvider || !platformProvider?.trim()) {
    // default provider is Docker
    platformProvider = "docker"
  }

  // We will decide whether to include the nightly tests in the execution at CI time, only.
  // On the other hand, the developers can use the TAGS environment variable locally.
  // Finally, we positively know that tags are not empty, so we can use AND operator.
  def excludeNightlyTag = " && ~${NIGHTLY_TAG}"
  if ("${NIGHTLY_SCENARIOS}" == "true") {
    excludeNightlyTag = ""
  }
  tags += excludeNightlyTag

  if (isPR() || isUpstreamTrigger(filter: 'PR-')) {
    // when the "Run_As_Master_Branch" param is disabled, we will honour the PR filters, which
    // basically exclude some less frequent platforms or operative systems. If the user enabled
    // this param, the pipeline will remove the filters from the test runner.
    if (!params.Run_As_Master_Branch) {
      tags += pullRequestFilter
    }
  }

  def goArch = "amd64"
  if (platformLabels.contains("arm64") || platformLabels.contains("aarch64")) {
    goArch = "arm64"
  }

  if (platformLabels.contains("windows")) {
    tags += " && ~@skip:windows"
  }

  // Skip scenarios per platform
  tags += " && ~@skip:${goArch}"

  // Setup environment for platform
  def envContext = []
  envContext.add("GOARCH=${goArch}")
  envContext.add("PROVIDER=${platformProvider}")
  envContext.add("ELASTIC_APM_GLOBAL_LABELS=branch_name=${BRANCH_NAME},build_pr=${isPR()},build_id=${env.BUILD_ID},go_arch=${goArch},beat_version=${env.BEAT_VERSION},stack_version=${env.STACK_VERSION}")
  envContext.add("OP_LOG_LEVEL=TRACE")
  envContext.add("LOG_LEVEL=TRACE")

  if (platformProvider == "remote" && endpointMap) {
      envContext.add("KIBANA_URL=${endpointMap.kibanaUrl}")
      envContext.add("ELASTICSEARCH_URL=${endpointMap.elasticsearchUrl}")
      envContext.add("FLEET_URL=${endpointMap.fleetUrl}")
  }

  return {
    withNode(labels: "${platformLabels}", sleepMax: 20, forceWorkspace: true){
      deleteDir()
      unstash 'source'
      try {
          dir("${BASE_DIR}") {
            if (platformLabels.contains("windows")) {
              def mingwArch = is32() ? '32' : '64'
              def chocoPath = 'C:\\ProgramData\\chocolatey\\bin'
              def chocoPython3Path = 'C:\\Python38;C:\\Python38\\Scripts'
              path = "${env.WORKSPACE}\\bin;${chocoPath};${chocoPython3Path};C:\\tools\\mingw${mingwArch}\\bin;C:\\windows\\system32;C:\\windows\\system32\\WindowsPowerShell\\v1.0\\"
              envContext.add("PATH=${path}")
              echo "The PATH is: ${PATH}; Provider is: ${PROVIDER}; KIBANA URL: ${KIBANA_URL}; ES URL: ${ELASTICSEARCH_URL}; FLEET URL: ${FLEET_URL}"
              powershell label: "Disk Information", script: "Get-PSDrive"
              powershell label: "Pinging Linux VM", script: "ping -n 1 ${linuxIp}"
              powershell label: "Check for running elasticsearch", script: "Test-NetConnection ${linuxIp} -Port 9200"
              powershell label: "Check for running kibana", script: "Test-NetConnection ${linuxIp} -Port 5601"
              powershell label: "Check for running fleet server", script: "Test-NetConnection ${linuxIp} -Port 8220"
           }
           withEnv(envContext) {
              if (platformLabels.contains("windows")) {
                // Boot up a windows VM to deploy Elastic Agent to be tested against
                // a remote deployed stack
                withGoEnvWindows(version: "${GO_VERSION}"){
                  cmd script: "cd e2e\\_suites\\${suite} && go test -timeout 60m -v --godog.tags=\"${tags}\"", label: "Run functional tests for ${platformLabels}:${suite}:${tags}"
                }
              } else {
                withGoEnv(version: "${GO_VERSION}") {
                  // This step will help to send the APM traces to the
                  // APM service defined by the Otel Jenkins plugin.
                  withOtelEnv() {
                      sh script: """.ci/scripts/functional-test.sh "${suite}" "${tags}" "${STACK_VERSION}" "${BEAT_VERSION}" """, label: "Run functional tests for ${platformLabels}:${suite}:${tags}"
                  }
                }
             }
          }
        }
      } finally {
        junit(allowEmptyResults: true, keepLongStdio: true, testResults: "${BASE_DIR}/outputs/TEST-*.xml")
        archiveArtifacts allowEmptyArchive: true, artifacts: "${BASE_DIR}/outputs/TEST-*.xml"
        tearDown(labels: platformLabels)
      }
    }
  }
}

def grabWorkerIP(){
  def linuxIp = ''
  retryWithSleep(retries: 3, seconds: 5, backoff: true){
    linuxIp = sh(label: 'Get IP', script: '''hostname -I | awk '{print $1}' ''', returnStdout: true)?.trim()
    log(level: 'INFO', text: "Worker IP '${linuxIp}'")
    if(!linuxIp?.trim()){
      error('Unable to get the Linux worker IP')
    }
  }
  return linuxIp
}


/**
* Tear down the setup for the static workers.
*/
def tearDown(Map args = [:]){
  catchError(buildResult: 'SUCCESS', stageResult: 'SUCCESS') {
    dir("${BASE_DIR}"){
      sh(label: 'Remove the entire module cache', script: 'go clean -modcache', returnStatus: true)
    }
    if (isStaticWorker(labels: args.labels)) {
      dir("${WORKSPACE}") {
        deleteDir()
      }
    }
  }
}

/**
 Notify the GitHub check of the parent stream
**/
def githubCheckNotify(String status) {
  if (params.GITHUB_CHECK_NAME?.trim() && params.GITHUB_CHECK_REPO?.trim() && params.GITHUB_CHECK_SHA1?.trim()) {
    githubNotify context: "${params.GITHUB_CHECK_NAME}",
                 description: "${params.GITHUB_CHECK_NAME} ${status.toLowerCase()}",
                 status: "${status}",
                 targetUrl: "${env.RUN_DISPLAY_URL}",
                 sha: params.GITHUB_CHECK_SHA1, account: 'elastic', repo: params.GITHUB_CHECK_REPO, credentialsId: env.JOB_GIT_CREDENTIALS
  }
}
