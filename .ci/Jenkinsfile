#!/usr/bin/env groovy

@Library('apm@current') _

import groovy.transform.Field

/**
Store the worker status so if the CI worker behaves wrongy then let's rerun the stage again
*/
@Field def workersStatus = [:]

pipeline {
  agent { label 'ubuntu-20.04 && immutable && docker' }
  environment {
    REPO = 'e2e-testing'
    BASE_DIR = "src/github.com/elastic/${env.REPO}"
    REAL_BASE_DIR = "${env.WORKSPACE}/${env.BASE_DIR}"
    ELASTIC_APM_ACTIVE="true"
    ELASTIC_APM_ENVIRONMENT="ci"
    ELASTIC_APM_LOG_FILE="stderr"
    ELASTIC_APM_LOG_LEVEL="debug"
    NOTIFY_TO = credentials('notify-to')
    JOB_GCS_BUCKET = credentials('gcs-bucket')
    JOB_GIT_CREDENTIALS = "2a9602aa-ab9f-4e52-baf3-b71ca88469c7-UserAndToken"
    DOCKER_ELASTIC_SECRET = 'secret/observability-team/ci/docker-registry/prod'
    DOCKER_REGISTRY = 'docker.elastic.co'
    ELASTIC_CLOUD_SECRET = 'secret/observability-team/ci/elastic-cloud/observability-team-user'
    GCP_PROVISIONER_SECRET = 'secret/observability-team/ci/service-account/jenkins-gce-provisioner'
    AWS_PROVISIONER_SECRET = 'secret/observability-team/ci/elastic-observability-aws-account-auth'
    TEST_MATRIX_FILE = "${params.testMatrixFile}"
    E2E_SSH_KEY = "${env.REAL_BASE_DIR}/e2essh"
    E2E_SSH_KEY_PUB = "${env.E2E_SSH_KEY}.pub"
  }
  options {
    timeout(time: 120, unit: 'MINUTES')
    buildDiscarder(logRotator(numToKeepStr: '200', artifactNumToKeepStr: '30', daysToKeepStr: '30'))
    timestamps()
    ansiColor('xterm')
    disableResume()
    durabilityHint('PERFORMANCE_OPTIMIZED')
    rateLimitBuilds(throttle: [count: 60, durationName: 'hour', userBoost: true])
    quietPeriod(10)
  }
  triggers {
    issueCommentTrigger("${obltGitHubComments()}")
  }
  parameters {
    booleanParam(name: 'Run_As_Main_Branch', defaultValue: false, description: 'Allow to run any steps on a PR, some steps normally only run on main branch.')
    booleanParam(name: "DESTROY_CLOUD_RESOURCES", defaultValue: true, description: "If checked, cloud resources will be destroyed at the end of the pipeline. Default true")
    booleanParam(name: "SKIP_SCENARIOS", defaultValue: true, description: "If it's needed to skip those scenarios marked as @skip. Default true")
    booleanParam(name: "NIGHTLY_SCENARIOS", defaultValue: false, description: "Deprecated. Not used in this pipeline any more. Please refer to the 'testMatrixFile' param, which defines what scenarios to run")
    string(name: 'runTestsSuites', defaultValue: '', description: 'A comma-separated list of test suites to run (default: empty to run all test suites)')
    string(name: 'testMatrixFile', defaultValue: '.ci/.e2e-tests.yaml', description: 'The file with the test suite and scenarios to be tested.')
    booleanParam(name: "forceSkipGitChecks", defaultValue: false, description: "If it's needed to check for Git changes to filter by modified sources")
    booleanParam(name: "notifyOnGreenBuilds", defaultValue: false, description: "If it's needed to notify to Slack with green builds.")
    string(name: 'SLACK_CHANNEL', defaultValue: 'observablt-bots', description: 'The Slack channel(s) where errors will be posted. For multiple channels, use a comma-separated list of channels')
    string(name: 'ELASTIC_AGENT_DOWNLOAD_URL', defaultValue: '', description: 'If present, it will override the download URL for the Elastic agent artifact. (I.e. https://snapshots.elastic.co/8.8.2-0c8e2646-SNAPSHOT-linux-x86_64.tar.gz')
    string(name: 'ELASTIC_AGENT_VERSION', defaultValue: '8.8.2-0c8e2646-SNAPSHOT', description: 'SemVer version of the Elastic Agent to be used for the tests. You can use here the tag of your PR to test your changes')
    string(name: 'BEAT_VERSION', defaultValue: '8.8.2-0c8e2646-SNAPSHOT', description: 'SemVer version of the Beat to be used for the tests. You can use here the tag of your PR to test your changes')
    choice(name: 'LOG_LEVEL', choices: ['INFO', 'DEBUG', 'TRACE'], description: 'Log level to be used')
    choice(name: 'TIMEOUT_FACTOR', choices: ['5', '3', '7', '11'], description: 'Max number of minutes for timeout backoff strategies')
    string(name: 'KIBANA_VERSION', defaultValue: '', description: 'Docker tag of the kibana to be used for the tests. It will refer to an image related to a Kibana PR, under the Observability-CI namespace')
    string(name: 'STACK_VERSION', defaultValue: '8.8.2-0c8e2646-SNAPSHOT', description: 'SemVer version of the stack to be used for the tests.')
    string(name: 'HELM_CHART_VERSION', defaultValue: '7.17.3', description: 'SemVer version of Helm chart to be used.')
    string(name: 'HELM_VERSION', defaultValue: '3.9.0', description: 'SemVer version of Helm to be used.')
    string(name: 'KIND_VERSION', defaultValue: '0.17.0', description: 'SemVer version of Kind to be used.')
    string(name: 'KUBERNETES_VERSION', defaultValue: '1.26.0', description: 'SemVer version of Kubernetes to be used.')
    string(name: 'GITHUB_CHECK_NAME', defaultValue: '', description: 'Name of the GitHub check to be updated. Only if this build is triggered from another parent stream.')
    string(name: 'GITHUB_CHECK_REPO', defaultValue: 'elastic-agent', description: 'Name of the GitHub repo to be updated. Only modified if this build is triggered from another parent stream (i.e. Beats).')
    string(name: 'GITHUB_CHECK_SHA1', defaultValue: '', description: 'Git SHA for the upstream project (branch or PR)')
  }
  stages {
    stage('Initializing'){
      options { skipDefaultCheckout() }
      environment {
        HOME = "${env.WORKSPACE}"
        PATH = "${env.PATH}:${env.WORKSPACE}/bin:${env.REAL_BASE_DIR}/.ci/scripts"
        GO111MODULE = 'on'
        SKIP_SCENARIOS = "${params.SKIP_SCENARIOS}"
        SLACK_CHANNEL = "${params.SLACK_CHANNEL.trim()}"
        ELASTIC_AGENT_DOWNLOAD_URL = "${params.ELASTIC_AGENT_DOWNLOAD_URL.trim()}"
        BEAT_VERSION = "${params.BEAT_VERSION.trim()}"
        ELASTIC_AGENT_VERSION = "${params.ELASTIC_AGENT_VERSION.trim()}"
        KIBANA_VERSION = "${params.KIBANA_VERSION.trim()}"
        STACK_VERSION = "${params.STACK_VERSION.trim()}"
        FORCE_SKIP_GIT_CHECKS = "${params.forceSkipGitChecks}"
        HELM_VERSION = "${params.HELM_VERSION.trim()}"
        KIND_VERSION = "${params.KIND_VERSION.trim()}"
        KUBERNETES_VERSION = "${params.KUBERNETES_VERSION.trim()}"
        LOG_LEVEL = "${params.LOG_LEVEL.trim()}"
        TIMEOUT_FACTOR = "${params.TIMEOUT_FACTOR.trim()}"
        GITHUB_CHECK_REPO = "${params.GITHUB_CHECK_REPO.trim()}"
        GITHUB_CHECK_SHA1 = "${params.GITHUB_CHECK_SHA1.trim()}"
      }
      stages {
        stage('Checkout') {
          steps {
            pipelineManager([ cancelPreviousRunningBuilds: [ when: 'PR' ] ])
            deleteDir()
            gitCheckout(basedir: BASE_DIR, githubNotifyFirstTimeContributor: true)
            githubCheckNotify('PENDING')  // we want to notify the upstream about the e2e the soonest
            stash allowEmpty: true, name: 'source', useDefaultExcludes: false
            setEnvVar("GO_VERSION", readFile("${env.REAL_BASE_DIR}/.go-version").trim())
            setEnvVar("LABELS_STRING", "buildURL=${env.BUILD_URL} gitSha=${env.GIT_BASE_COMMIT} build=${env.BUILD_ID} repo=${env.REPO} branch=${env.BRANCH_NAME.toLowerCase().replaceAll('[^a-z0-9-]', '-')} type=ci")
            checkSkipTests()
          }
        }
        stage('Build Docs') {
          options { skipDefaultCheckout() }
          when {
            beforeAgent true
            anyOf {
              expression { return env.FORCE_SKIP_GIT_CHECKS == "true" }
              expression { return env.SKIP_TESTS == "false" }
            }
          }
          steps {
            dockerLogin(secret: "${DOCKER_ELASTIC_SECRET}", registry: "${DOCKER_REGISTRY}")
            dir("${BASE_DIR}/e2e") {
              sh(label: 'Build docs', script: 'make build-docs')
            }
          }
          post {
            always {
              dir("${BASE_DIR}") {
                archiveArtifacts allowEmptyArchive: true, artifacts: "e2e/docs/**"
              }
            }
          }
        }
        stage('Deploy Test Infra') {
          failFast true
          options { skipDefaultCheckout() }
          environment {
            GO111MODULE = 'on'
            PATH = "${env.HOME}/bin:${env.REAL_BASE_DIR}/bin:${HOME}/go/bin:${env.PATH}"
          }
          when {
            beforeAgent true
            anyOf {
              expression { return env.FORCE_SKIP_GIT_CHECKS == "true" }
              expression { return env.SKIP_TESTS == "false" }
            }
          }
          steps {
            withGithubNotify(context: 'Deploy Stack', tab: 'tests') {
              deleteDir()
              unstash 'source'
              script {
                // Deploy the test infrastructure
                sh "ssh-keygen -b 4096 -t rsa -f ${E2E_SSH_KEY} -q -N \"\" "

                dir("${env.REAL_BASE_DIR}") {
                  withEnv([
                    "SUITE=fleet",
                    "STACK_INSTANCE_ID=${env.BUILD_URL}_stack",
                    "TAGS=non-existing-tag"
                  ]) {
                    ciBuild() {
                      retryWithSleep(retries: 3, seconds: 5, backoff: true){
                        sh(label: 'Setup Stack node', script: "make -C .ci create-stack")
                      }
                    }
                  }

                  // Update stash with latest changes from the stack deployment
                  stash allowEmpty: true, name: 'sourceEnvModified', useDefaultExcludes: false, excludes: '.ansible, .runID'
                }
              }
            }
          }
        }

        stage('End-To-End Tests') {
          failFast true
          options { skipDefaultCheckout() }
          environment {
            GO111MODULE = 'on'
            PATH = "${env.HOME}/bin:${env.REAL_BASE_DIR}/bin:${HOME}/go/bin:${env.PATH}"
          }
          when {
            beforeAgent true
            anyOf {
              expression { return env.FORCE_SKIP_GIT_CHECKS == "true" }
              expression { return env.SKIP_TESTS == "false" }
            }
          }
          steps {
            withGithubNotify(context: 'E2E Tests', tab: 'tests') {
              script {
                def suitesParam = params.runTestsSuites
                def existingSuites = readYaml(file: "${env.REAL_BASE_DIR}/${TEST_MATRIX_FILE}")
                def parallelTasks = [:]
                if (suitesParam == "") {
                  log(level: 'DEBUG', text: "Iterate through existing test suites")
                  existingSuites['SUITES'].each { item ->
                    checkTestSuite(parallelTasks, item)
                  }
                } else {
                  log(level: 'DEBUG', text: "Iterate through the comma-separated test suites (${suitesParam}), comparing with the existing test suites")
                  suitesParam.split(',').each { suiteParam ->
                    existingSuites['SUITES'].findAll { suiteParam.trim() == it.suite }.each { item ->
                      checkTestSuite(parallelTasks, item)
                    }
                  }
                }
                parallel(parallelTasks)
              }
            }
          }
          post {
            cleanup {
              // Once all tests are complete we need to teardown the single instance with the deployed stack
              script {
                dir("${env.REAL_BASE_DIR}") {
                  ciBuild() {
                    def stackIP = getNodeIp('stack')
                    sh(label: 'Grab logs', script:"make -C .ci fetch-test-reports NODE_IP_ADDRESS=${stackIP} NODE_LABEL=debian_10_amd64")
                    archiveArtifacts(allowEmptyArchive: true, artifacts: "outputs/**/TEST-*,outputs/**/*.zip,outputs/**/*.tgz")
                    junit2otel(traceName: 'junit-e2e-tests', allowEmptyResults: true, keepLongStdio: true, testResults: "outputs/**/TEST-*.xml")
                  }
                }
                def stackMachine = getMachineInfo('stack')
                if (!params.DESTROY_CLOUD_RESOURCES) {
                  def stackRunnerIP = getNodeIp('stack')
                  log(level: 'DEBUG', text: "Stack instance won't be destroyed after the build. Please SSH into the stack machine on ${stackRunnerIP}")
                } else {
                  dir("${env.REAL_BASE_DIR}") {
                    withEnv([
                      "STACK_INSTANCE_ID=${env.BUILD_URL}_stack",
                    ]) {
                      ciBuild() {
                        retryWithSleep(retries: 3, seconds: 5, backoff: true){
                          sh(label: 'Destroy stack node', script: "make -C .ci destroy-stack")
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
        stage('Release') {
          options { skipDefaultCheckout() }
          when { tag "v*" }
          steps {
            deleteDir()
            unstash 'source'
            dir("${BASE_DIR}") {
              setEnvVar("GITHUB_TOKEN", getGithubToken())
              retryWithSleep(retries: 2, seconds: 5, backoff: true) {
                sh(label: 'Release binaries with gorelease', script: 'curl -sL https://git.io/goreleaser | bash -s -- --rm-dist', returnStatus: true)
              }
            }
          }
          post {
            always {
              archiveArtifacts allowEmptyArchive: true, artifacts: "${BASE_DIR}/cli/dist/**"
            }
          }
        }
      }
    }
  }
  post {
    cleanup {
      doNotifyBuildResult(params.notifyOnGreenBuilds)
    }
  }
}

// this function evaluates if the test stage of the build must be executed
def checkSkipTests() {
  dir("${BASE_DIR}"){

    // only docs means no tests are run
    if (isGitRegionMatch(patterns: [ '.*\\.md' ], shouldMatchAll: true)) {
      setEnvVar("SKIP_TESTS", true)
      return
    }

    // patterns for all places that should trigger a full build
    def regexps = [ "^e2e/_suites/fleet/.*", "^e2e/_suites/kubernetes-autodiscover/.*", "^.ci/.*", "^cli/.*", "^e2e/.*\\.go", "^internal/.*\\.go" ]
    setEnvVar("SKIP_TESTS", !isGitRegionMatch(patterns: regexps, shouldMatchAll: false))
  }
}

/*
 * Runs the Make build at the CI, executing the closure in the context of Ansible + AWS
 */
def ciBuild(Closure body){
  withEnv([
    "SSH_KEY=${E2E_SSH_KEY}"
  ]) {
    def awsProps = getVaultSecret(secret: "${AWS_PROVISIONER_SECRET}")
    def awsAuthObj = awsProps?.data
    withEnv([
      "ANSIBLE_CONFIG=${env.REAL_BASE_DIR}/.ci/ansible/ansible.cfg",
      "ANSIBLE_HOST_KEY_CHECKING=False",
    ]){
      withVaultToken(){
        withEnvMask(vars: [
          [var: "AWS_ACCESS_KEY_ID", password: awsAuthObj.access_key],
          [var: "AWS_SECRET_ACCESS_KEY", password: awsAuthObj.secret_key]
        ]) {
          withOtelEnv() {
            body()
          }
        }
      }
    }
  }
}

def getNodeIp(nodeType){
  return sh(label: "Get IP address of the ${nodeType}", script: "cat ${REAL_BASE_DIR}/.ci/.${nodeType}-host-ip", returnStdout: true)
}

def getRemoteE2EPath(testRunner, platform) {
  if (platform.contains("windows")) {
    return "C:\\Users\\${testRunner.user}\\e2e-testing\\"
  }

  return "/home/${testRunner.user}/e2e-testing/"
}

def getMachineInfo(platform){
  def machineYaml = readYaml(file: "${env.REAL_BASE_DIR}/.ci/.e2e-platforms.yaml")
  def machines = machineYaml['PLATFORMS']
  log(level: 'INFO', text: "getMachineInfo: machines.get(platform)=${machines.get(platform)}")
  return machines.get(platform)
}

def checkTestSuite(Map parallelTasks = [:], Map item = [:]) {
  def suite = item.suite
  def platforms = item.platforms

  // Predefine the remote provider to use the already provisioned stack VM.
  // Each suite or scenario in the CI test suite would be able to define its own provider
  // (i.e. docker). If empty, remote will be used as fallback
  def suiteProvider = item.provider
  if (!suiteProvider || suiteProvider?.trim() == '') {
    suiteProvider = 'remote'
  }

  item.scenarios.each { scenario ->
    def name = scenario.name
    def platformsValue = platforms

    def scenarioProvider = scenario.provider
    // if the scenario does not set its own provider, use suite's provider
    if (!scenarioProvider || scenarioProvider?.trim() == '') {
      scenarioProvider = suiteProvider
    }

    def scenarioPlatforms = scenario.platforms
    if (scenarioPlatforms?.size() > 0) {
      // scenario platforms take precedence over suite platforms, overriding them
      platformsValue = scenarioPlatforms
    }
    def pullRequestFilter = scenario.containsKey('pullRequestFilter') ? scenario.pullRequestFilter : ''
    def tags = scenario.tags
      platformsValue.each { rawPlatform ->
        // platform is not space based, so let's ensure no extra spaces can cause misbehaviours.
        def platform = rawPlatform.trim()
        log(level: 'INFO', text: "Adding ${suite}:${platform}:${tags} test suite to the build execution")
        def machineInfo = getMachineInfo(platform)
        def stageName = "${suite}_${platform}_${tags}"
        parallelTasks["${stageName}"] = generateFunctionalTestStep(name: "${name}",
                                                                  platform: platform,
                                                                  provider: scenarioProvider,
                                                                  suite: "${suite}",
                                                                  tags: "${tags}",
                                                                  pullRequestFilter: "${pullRequestFilter}",
                                                                  machine: machineInfo,
                                                                  stageName: stageName)
      }
  }
}

/*
 * Sends out notification of the build result to Slack
 */
def doNotifyBuildResult(boolean slackNotify) {
  def doSlackNotify = true // always try to notify on failures
  def githubCheckStatus = 'FAILURE'
  if (currentBuild.currentResult == 'SUCCESS') {
    githubCheckStatus = 'SUCCESS'
    doSlackNotify = slackNotify // if the build status is success, read the parameter
  }

  githubCheckNotify(githubCheckStatus)


  def testsSuites = "${params.runTestsSuites}"
  if (testsSuites?.trim() == "") {
    testsSuites = "All suites"
  }

  def channels = "${env.SLACK_CHANNEL}"
  if (channels?.trim() == "") {
    channels = "observablt-bots"
  }

  def header = "*Test Suite*: " + testsSuites
  notifyBuildResult(analyzeFlakey: true,
                    jobName: getFlakyJobName(withBranch: "${env.JOB_BASE_NAME}"),
                    prComment: true,
                    slackHeader: header,
                    slackChannel: "${channels}",
                    slackComment: true,
                    slackNotify: doSlackNotify)
}

/**
 Notify the GitHub check of the parent stream
 **/
def githubCheckNotify(String status) {
  if (params.GITHUB_CHECK_NAME?.trim() && params.GITHUB_CHECK_REPO?.trim() && params.GITHUB_CHECK_SHA1?.trim()) {
    githubNotify context: "${params.GITHUB_CHECK_NAME}",
      description: "${params.GITHUB_CHECK_NAME} ${status.toLowerCase()}",
      status: "${status}",
      targetUrl: "${env.RUN_DISPLAY_URL}",
      sha: params.GITHUB_CHECK_SHA1, account: 'elastic', repo: params.GITHUB_CHECK_REPO, credentialsId: env.JOB_GIT_CREDENTIALS
  }
}

def generateFunctionalTestStep(Map args = [:]){
  def name = args.get('name')
  def name_normalize = name.replace(' ', '_')
  def platform = args.get('platform')
  def provider = args.get('provider')
  def suite = args.get('suite')
  def tags = args.get('tags')
  def pullRequestFilter = args.get('pullRequestFilter')?.trim() ? args.get('pullRequestFilter') : ''
  def machine = args.get('machine')
  def stageName = args.get('stageName')

  // TODO: Is this still relevant?
  if (isPR() || isUpstreamTrigger(filter: 'PR-')) {
    // when the "Run_As_Main_Branch" param is disabled, we will honour the PR filters, which
    // basically exclude some less frequent platforms or operative systems. If the user enabled
    // this param, the pipeline will remove the filters from the test runner.
    if (!params.Run_As_Main_Branch) {
      tags += pullRequestFilter
    }
  }

  def goArch = "amd64"
  if (platform.contains("arm64")) {
    goArch = "arm64"
  }

  // sanitize tags to create the file
  def sanitisedTags = tags.replaceAll("\\s","_")
  sanitisedTags = sanitisedTags.replaceAll("~","")
  sanitisedTags = sanitisedTags.replaceAll("@","")

  def githubCheckSha1 = params.GITHUB_CHECK_SHA1?.trim() ? params.GITHUB_CHECK_SHA1 : ''
  def githubCheckRepo = params.GITHUB_CHECK_REPO?.trim() ? params.GITHUB_CHECK_REPO : ''

  // Setup environment for platform
  def envContext = []
  envContext.add("PROVIDER=${provider}")
  envContext.add("GITHUB_CHECK_SHA1=${githubCheckSha1}")
  envContext.add("GITHUB_CHECK_REPO=${githubCheckRepo}")
  envContext.add("SUITE=${suite}")
  envContext.add("TAGS=${tags}")
  envContext.add("REPORT_PREFIX=${suite}_${platform}_${sanitisedTags}")
  envContext.add("ELASTIC_APM_GLOBAL_LABELS=branch_name=${BRANCH_NAME},build_pr=${isPR()},build_id=${env.BUILD_ID},go_arch=${goArch},beat_version=${env.BEAT_VERSION},elastic_agent_version=${env.ELASTIC_AGENT_VERSION},stack_version=${env.STACK_VERSION}")
  // VM characteristics
  envContext.add("NODE_LABEL=${platform}")
  envContext.add("NODE_IMAGE=${machine.image}")
  envContext.add("NODE_INSTANCE_ID=${env.BUILD_URL}_${platform}_${suite}_${tags}")
  envContext.add("NODE_INSTANCE_TYPE=${machine.instance_type}")
  envContext.add("NODE_SHELL_TYPE=${machine.shell_type}")
  envContext.add("NODE_USER=${machine.username}")

  return {
    // Set the worker as flaky for the time being, this will be changed in the finally closure.
    setFlakyWorker(stageName)
    retryWithNode(labels: 'ubuntu-20.04 && gobld/machineType:e2-small', forceWorkspace: true, forceWorker: true, stageName: stageName){
      try {
        deleteDir()
        dir("${env.REAL_BASE_DIR}") {
          unstash 'sourceEnvModified'
          withEnv(envContext) {
            // This step will help to send the APM traces to the
            // withOtelEnv is the one that uses the APM service defined by the Otel Jenkins plugin.
            // withAPMEnv uses Vault to prepare the context.
            // IMPORTANT: withAPMEnv is now the one in used since withOtelEnv uses a specific Opentelemetry Collector at the moment.
            // TODO: This will need to be integrated into the provisioned VMs
            withAPMEnv() {
              // we are separating the different test phases to avoid recreating
              ciBuild() {
                  sh(label: 'Start node', script: "make -C .ci provision-node")
              }

              // make goal to run the tests, which is platform-dependant
              def runCommand = "run-tests"

              if (platform.contains("windows")) {
                runCommand = "run-tests-win"
                // Ansible wait_for module is not enough to mitigate the timeout
                log(level: 'DEBUG', text: "Sleeping 300 seconds on Windows so that SSH is accessible in the remote instance.")
                sleep(300)
              }

              ciBuild() {
                retryWithSleep(retries: 3, seconds: 5, backoff: true){
                  sh(label: 'Configure node for testing', script: "make -C .ci setup-node")
                }
              }
              ciBuild() {
                sh(label: 'Run tests in the node', script: "make -C .ci ${runCommand}")
              }
            }
          }
        }
      } finally {
        withEnv(envContext) {
          dir("${env.REAL_BASE_DIR}") {
            // If it reaches this point then the CI worker is most likely behaving correctly
            // there is still a chance things might fail afterwards, but this is just the finally
            // section so we could say we are good to go.
            // It runs after dir so if the worker is gone the an error will be thrown regarding
            // the dir cannot be accessed in the existing none worker.
            unsetFlakyWorker(stageName)
            def testRunnerIP = getNodeIp("node")
            sh "mkdir -p outputs/${testRunnerIP} || true"
            ciBuild() {
              sh(label: 'Fetch tests reports from node', script: "make -C .ci fetch-test-reports")
            }
            sh "ls -l outputs/${testRunnerIP}"
            if (!params.DESTROY_CLOUD_RESOURCES) {
              log(level: 'INFO', text: "Cloud instance won't be destroyed after the build. Please SSH into the test runner machine on ${testRunnerIP}.")
            } else {
              log(level: 'INFO', text: "Destroying Cloud instance")
              ciBuild() {
                retryWithSleep(retries: 3, seconds: 5, backoff: true){
                  sh(label: 'Destroy node', script: "make -C .ci destroy-node")
                }
              }
            }
            archiveArtifacts(allowEmptyArchive: true, artifacts: "outputs/**/TEST-*,outputs/**/*.zip,outputs/**/*.tgz")
            junit2otel(traceName: 'junit-e2e-tests', allowEmptyResults: true, keepLongStdio: true, testResults: "outputs/**/TEST-*.xml")
          }
        }
      }
    }
  }
}

def retryWithNode(Map args = [:], Closure body) {
  try {
    incrementRetries(args.stageName)
    withNode(args){
      body()
    }
  } catch (err) {
    log(level: 'WARN', text: "Stage '${args.stageName}' failed, let's analyse if it's a flaky CI worker.")
    if (isFlakyWorker(args.stageName) && isRetryAvailable(args.stageName)) {
      log(level: 'INFO', text: "Rerun '${args.stageName}' in a new worker.")
      retryWithNode(args) {
        body()
      }
    } else {
      error("Error '${err.toString()}'")
    }
  }
}

def isFlakyWorker(stageName) {
  if (workersStatus.containsKey(stageName)) {
    return !workersStatus.get(stageName).get('status', true)
  }
  return false
}

def isRetryAvailable(stageName) {
  return workersStatus.get(stageName).get('retries', 2) < 2
}

def incrementRetries(stageName) {
  if (workersStatus.containsKey(stageName)) {
    def current = workersStatus[stageName].get('retries', 0)
    workersStatus[stageName].retries = current + 1
  } else {
    setFlakyWorker(stageName)
    workersStatus[stageName].retries = 1
  }
}

def setFlakyWorker(stageName) {
  if (workersStatus.containsKey(stageName)) {
    workersStatus[stageName].status = false
  } else {
    workersStatus[stageName] = [ status: false ]
  }
}

def unsetFlakyWorker(stageName) {
  workersStatus[stageName].status = true
}
